# ======================
# ALPHADENT: COMPLETE PIPELINE (Fixed)
# ======================

# 1. GPU CHECK
import torch
if not torch.cuda.is_available():
    raise EnvironmentError("‚ùå GPU IS NOT ENABLED! Please go to Settings -> Accelerator -> Select GPU P100 or T4.")
else:
    print(f"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}")

# 2. INSTALL DEPENDENCIES (Fixed - removed problematic --no-deps)
!pip install -q ultralytics
!pip install -q sahi
!pip install -q pybboxes fire
!pip install -q pyyaml

# 3. IMPORTS
import os
import re
import cv2
import yaml
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from glob import glob
from tqdm import tqdm
import warnings
import gc
import psutil
import shutil
warnings.filterwarnings('ignore')

from ultralytics import YOLO
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction

# 4. DATASET & CONFIGURATION SETUP (FIXED PATHS)
# First, let's explore the actual directory structure
print("Exploring directory structure...")
for root, dirs, files in os.walk("/kaggle/input"):
    level = root.replace("/kaggle/input", "").count(os.sep)
    indent = " " * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = " " * 2 * (level + 1)
    for file in files[:5]:  # Show first 5 files only
        if file.endswith(('.yaml', '.yml')):
            print(f"{subindent}{file}")

# Try multiple possible paths for the dataset
possible_paths = [
    "/kaggle/input/alpha-dent/AlphaDent",
    "/kaggle/input/alphadent",
    "/kaggle/input/competitions/alpha-dent/AlphaDent",
    "/kaggle/input/alpha-dent"
]

DATA_ROOT = None
for path in possible_paths:
    if os.path.exists(path):
        DATA_ROOT = path
        print(f"‚úÖ Found dataset at: {DATA_ROOT}")
        break

if DATA_ROOT is None:
    raise FileNotFoundError("‚ùå Could not find AlphaDent dataset. Please check the input path.")

# Look for YAML file in multiple locations
yaml_paths = [
    f"{DATA_ROOT}/yolo_seg_train.yaml",
    f"{DATA_ROOT}/config/yolo_seg_train.yaml",
    f"{DATA_ROOT}/AlphaDent/yolo_seg_train.yaml",
    "/kaggle/input/alpha-dent/yolo_seg_train.yaml"
]

PROVIDED_YAML = None
for yaml_path in yaml_paths:
    if os.path.exists(yaml_path):
        PROVIDED_YAML = yaml_path
        print(f"‚úÖ Found YAML at: {PROVIDED_YAML}")
        break

# If YAML not found, create a default one
if PROVIDED_YAML is None:
    print("‚ö†Ô∏è YAML not found, creating default configuration...")
    
    # Check for images directory
    images_dir = None
    for possible_img_dir in [f"{DATA_ROOT}/images", f"{DATA_ROOT}/Images", DATA_ROOT]:
        if os.path.exists(possible_img_dir):
            images_dir = possible_img_dir
            break
    
    if images_dir is None:
        raise FileNotFoundError("‚ùå Could not find images directory")
    
    # Create default YAML configuration
    config = {
        'path': DATA_ROOT,
        'train': 'images/train',
        'val': 'images/valid',
        'test': 'images/test',
        'names': {
            0: 'tooth',
            1: 'cavity',
            2: 'filling'
        }
    }
    
    FIXED_YAML = "alpha_dent_config.yaml"
    with open(FIXED_YAML, 'w') as f:
        yaml.dump(config, f)
    print(f"‚úÖ Created default config: {FIXED_YAML}")
else:
    # Load and fix existing YAML
    print(f"Loading config from: {PROVIDED_YAML}")
    with open(PROVIDED_YAML, 'r') as f:
        config = yaml.safe_load(f)
    
    # Fix the path to ensure YOLO finds images
    config['path'] = DATA_ROOT
    
    # Save fixed config
    FIXED_YAML = "alpha_dent_fixed.yaml"
    with open(FIXED_YAML, 'w') as f:
        yaml.dump(config, f)
    print(f"‚úÖ Config fixed and saved to: {FIXED_YAML}")

# Define image paths - try multiple patterns
print("\nSearching for images...")
image_patterns = [
    f"{DATA_ROOT}/images/train/*.jpg",
    f"{DATA_ROOT}/Images/train/*.jpg",
    f"{DATA_ROOT}/train/*.jpg",
    f"{DATA_ROOT}/images/train/*.png",
    f"{DATA_ROOT}/Images/train/*.png",
    f"{DATA_ROOT}/train/*.png"
]

train_images = []
for pattern in image_patterns:
    train_images = sorted(glob(pattern))
    if train_images:
        print(f"‚úÖ Found train images with pattern: {pattern}")
        break

val_patterns = [
    f"{DATA_ROOT}/images/valid/*.jpg",
    f"{DATA_ROOT}/images/val/*.jpg",
    f"{DATA_ROOT}/Images/valid/*.jpg",
    f"{DATA_ROOT}/valid/*.jpg",
    f"{DATA_ROOT}/val/*.jpg",
    f"{DATA_ROOT}/images/valid/*.png",
    f"{DATA_ROOT}/images/val/*.png"
]

val_images = []
for pattern in val_patterns:
    val_images = sorted(glob(pattern))
    if val_images:
        print(f"‚úÖ Found val images with pattern: {pattern}")
        break

test_patterns = [
    f"{DATA_ROOT}/images/test/*.jpg",
    f"{DATA_ROOT}/Images/test/*.jpg",
    f"{DATA_ROOT}/test/*.jpg",
    f"{DATA_ROOT}/images/test/*.png",
    f"{DATA_ROOT}/Images/test/*.png",
    f"{DATA_ROOT}/test/*.png"
]

test_images = []
for pattern in test_patterns:
    test_images = sorted(glob(pattern))
    if test_images:
        print(f"‚úÖ Found test images with pattern: {pattern}")
        break

print(f"\nDataset Summary:")
print(f"Train images: {len(train_images)}")
print(f"Val images: {len(val_images)}")
print(f"Test images: {len(test_images)}")

if len(train_images) == 0:
    print("‚ö†Ô∏è Warning: No training images found!")

# 5. METADATA CREATION
def extract_age(filename):
    patterns = [r'patient_(\d+)', r'age_(\d+)', r'(\d+)_\d+\.jpg', r'(\d+)_\d+\.png']
    for pattern in patterns:
        match = re.search(pattern, filename)
        if match:
            return int(match.group(1))
    return None

metadata = []
all_images = train_images + val_images + test_images
for img_path in all_images:
    age = extract_age(os.path.basename(img_path))
    metadata.append({
        "image_path": img_path,
        "age": age,
        "split": "train" if "train" in img_path else "val" if "val" in img_path or "valid" in img_path else "test"
    })

metadata_df = pd.DataFrame(metadata)
metadata_df.to_csv("metadata.csv", index=False)
print(f"‚úÖ Metadata created with {len(metadata_df)} entries")

# 6. TRI-MODAL PREPROCESSING
def apply_clahe(img, clip_limit=None, grid_size=(8, 8)):
    if clip_limit is None:
        brightness = np.mean(img)
        clip_limit = 1.0 + (brightness / 255) * 2.0
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)
    return clahe.apply(img)

def apply_sobel(img):
    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)
    sobel = np.sqrt(sobelx**2 + sobely**2)
    sobel = cv2.normalize(sobel, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    _, sobel = cv2.threshold(sobel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return sobel

def tri_modal_preprocess(img_path):
    try:
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError(f"Failed to read image at {img_path}")
            
        gray = img.copy()
        clahe = apply_clahe(img)
        sobel = apply_sobel(img)
        return np.stack([gray, clahe, sobel], axis=-1)
    except Exception as e:
        print(f"Preprocessing error: {e}")
        # Return a default image
        return np.zeros((640, 640, 3), dtype=np.uint8)

# 7. TRAINING (Only if we have training data)
def train_model():
    print("\nüöÄ Starting YOLOv8-Seg Training...")
    
    # Try different model sizes based on available memory
    try:
        model = YOLO("yolov8x-seg.pt")
    except:
        print("Large model failed, trying medium...")
        model = YOLO("yolov8m-seg.pt")
    
    results = model.train(
        data=FIXED_YAML,
        epochs=50,  # Reduced for faster testing
        imgsz=640,
        batch=8,    # Reduced batch size
        device=0,
        augment=True,
        patience=10,
        optimizer="AdamW",
        lr0=0.001,
        name="alpha_dent_final",
        verbose=True,
        exist_ok=True  # Continue from checkpoint if exists
    )
    return model

# Only train if we have training images
if len(train_images) > 0:
    model = train_model()
else:
    print("‚ö†Ô∏è No training images found, loading pretrained model...")
    model = YOLO("yolov8m-seg.pt")

# 8. INFERENCE FUNCTIONS
def standard_inference(img_path, model_instance):
    try:
        tri_modal_img = tri_modal_preprocess(img_path)
        results = model_instance.predict(tri_modal_img, imgsz=640, conf=0.25, verbose=False)
        return results[0].plot()
    except Exception as e:
        print(f"Inference Error: {e}")
        img = cv2.imread(img_path)
        return img if img is not None else np.zeros((640, 640, 3), dtype=np.uint8)

def sahi_inference(img_path, model_path):
    try:
        img = cv2.imread(img_path)
        if img is None:
            return np.zeros((640, 640, 3), dtype=np.uint8)
            
        h, w = img.shape[:2]
        slice_size = min(640, h, w)

        detection_model = AutoDetectionModel.from_pretrained(
            model_type="yolov8",
            model_path=model_path,
            confidence_threshold=0.25,
            device="cuda:0"
        )

        tri_modal_img = tri_modal_preprocess(img_path)
        
        results = get_sliced_prediction(
            tri_modal_img,
            detection_model,
            slice_height=slice_size,
            slice_width=slice_size,
            overlap_height_ratio=0.2,
            overlap_width_ratio=0.2,
        )

        img_vis = img.copy()
        for pred in results.object_prediction_list:
            box = pred.bbox.to_xyxy()
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(img_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)
        return img_vis
    except Exception as e:
        print(f"SAHI Error: {e}")
        return cv2.imread(img_path) if os.path.exists(img_path) else np.zeros((640, 640, 3), dtype=np.uint8)

def metadata_aware_inference(img_path, metadata_df, model_instance):
    try:
        img_name = os.path.basename(img_path)
        age_rows = metadata_df[metadata_df["image_path"].str.contains(re.escape(img_name))]
        age = age_rows["age"].values[0] if not age_rows.empty else None
        
        tri_modal_img = tri_modal_preprocess(img_path)
        results = model_instance.predict(tri_modal_img, imgsz=640, conf=0.25, verbose=False)
        return results[0].plot()
    except Exception as e:
        print(f"Metadata inference error: {e}")
        return np.zeros((640, 640, 3), dtype=np.uint8)

# 9. GENERATE RESULTS
print("\nüìä Generating Visualizations...")

# Select a sample image
sample_img = None
if len(test_images) > 0:
    sample_img = test_images[0]
elif len(val_images) > 0:
    sample_img = val_images[0]
elif len(train_images) > 0:
    sample_img = train_images[0]

if sample_img:
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Standard
    res_std = standard_inference(sample_img, model)
    axes[0].imshow(cv2.cvtColor(res_std, cv2.COLOR_BGR2RGB))
    axes[0].set_title("Standard")
    axes[0].axis('off')
    
    # SAHI
    best_weights = "runs/segment/alpha_dent_final/weights/best.pt"
    if os.path.exists(best_weights):
        res_sahi = sahi_inference(sample_img, best_weights)
        axes[1].imshow(cv2.cvtColor(res_sahi, cv2.COLOR_BGR2RGB))
    else:
        axes[1].text(0.5, 0.5, "No Weights Found", ha='center', va='center')
    axes[1].set_title("SAHI")
    axes[1].axis('off')
    
    # Metadata
    res_meta = metadata_aware_inference(sample_img, metadata_df, model)
    axes[2].imshow(cv2.cvtColor(res_meta, cv2.COLOR_BGR2RGB))
    axes[2].set_title("Metadata-Aware")
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.savefig("final_results.png")
    plt.show()
else:
    print("‚ö†Ô∏è No images found for visualization")

print("\n‚úÖ DONE!")